{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"r6BIAFG_gT-1"},"outputs":[],"source":["import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","import sys\n","import os\n","_stderr = sys.stderr\n","null = open(os.devnull,'wb')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41675,"status":"ok","timestamp":1683286004950,"user":{"displayName":"Alejandro Agudelo","userId":"03047800831023979194"},"user_tz":-120},"id":"eSi4kUUlgT-2","outputId":"a25d29eb-2f52-46b6-dc00-7d79513a82c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 pynndescent==0.5.10\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import scanpy as sc\n","import loompy\n","\n","# from scipy.sparse import csr_matrix, vstack\n","sc.settings.verbosity\n","sc.logging.print_header()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lP_xiZ4gT-3"},"outputs":[],"source":["work_dir = '/content/drive/MyDrive/TFM/TFM/hysteresis_project/scenic_run/'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9iIr-QhhgT-4"},"source":["# scRNA-seq preprocessing using Scanpy\n","\n","First, we preprocess the scRNA-seq side of the multiome datasets. Most importantly we will use this side of the data to annotate cell types.\n","\n","Further on, to use the actual SCENIC+ analysis the raw count matrix will be used."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JT54dQ4WgT-4"},"outputs":[],"source":["path = work_dir + 'filtered_data'\n","\n","adata = sc.read_mtx(\n","    path + 'matrix.mtx.gz').T  # transpose the matrix\n","adata.var_names = pd.read_csv(\n","    path + 'features.tsv.gz',\n","    header=None, sep='\\t').iloc[:, 0]\n","adata.obs_names = pd.read_csv(\n","    path + 'barcodes.tsv.gz',\n","    header=None).iloc[:, 0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEF_36d2gT-5"},"outputs":[],"source":["adata.var_names_make_unique()\n","adata.X"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"V5XcrFJkgT-5"},"source":["## Basic Quality Control\n","\n","Keep cells with at least 200 genes expressed and only keep genes which are expressed in at least 3 cells. Also, cells with a maximum of 20000 genes expressed and minimum 750 counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O0Uov_EHgT-6"},"outputs":[],"source":["sc.pp.filter_cells(adata, min_genes = 200)\n","sc.pp.filter_genes(adata, min_cells = 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgUzXC_mgT-6"},"outputs":[],"source":["sc.pp.filter_cells(adata, max_counts = 20000)\n","sc.pp.filter_cells(adata, min_counts = 750)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7mfNiMEngT-7"},"outputs":[],"source":["#Predicting doublets in the scRNA-seq\n","\n","import scrublet as scr\n","\n","scrub = scr.Scrublet(adata.X)\n","doublet_scores, predicted_doublets = scrub.scrub_doublets()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwRuk-xcgT-7"},"outputs":[],"source":["##As the doublets estimation is 0.0%, it does not really filter anything, but if there were any, it would filter them. \n","# Add predicted_doublets to adata.obs\n","adata.obs['predicted_doublets'] = predicted_doublets\n","\n","# Filter adata based on predicted_doublets\n","adata = adata[adata.obs['predicted_doublets'] == False]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6neadRpgT-8"},"outputs":[],"source":["#Compute different metrics (in this case, mitochondrial genes and ribosomal genes) with sc.pp_qc_metrics\n","\n","#Mitochondrial genes for all the samples\n","adata.var['mt'] = adata.var_names.str.startswith('mt-')  # annotate the group of mitochondrial genes as 'mt'\n","sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n","\n","#Ribosomal genes for all the samples\n","adata.var['Rp'] = adata.var_names.str.startswith('Rp')  # annotate the group of mitochondrial genes as 'mt'\n","sc.pp.calculate_qc_metrics(adata, qc_vars=['Rp'], percent_top=None, log1p=False, inplace=True)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"isPYWqXKgT-8"},"outputs":[],"source":["sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_Rp'], jitter=0.4, multi_panel=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ge3qAMaFgT-8"},"source":["## Data Normalization\n","\n","The data normalization and scalation is only for visualizing the data. For the SCENIC+ pipeline, we will use the raw count matrix. For that, first we save the non-normalized and non-scale AnnData object in the raw slot before continuing. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3JUryMbsgT-9"},"outputs":[],"source":["adata.raw = adata\n","sc.pp.normalize_total(adata, target_sum=1e4)\n","sc.pp.log1p(adata)\n","sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n","adata = adata[:, adata.var.highly_variable]\n","sc.pp.scale(adata, max_value=10)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wtTcpzrFgT-9"},"source":["## Cell type annotation\n","\n","This is the difference between SCENIC and SCENIC+. With using the annotation in the scRNA-seq data, we can use it to annotate the cells and use then the scATAC-seq data to do a more accurate analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g6v-YNBHgT-9"},"outputs":[],"source":["#Importing the tsv metadata file that we got from the Seurat object using the function Seurat_to_MM10X\n","import anndata as ad\n","\n","metadata_df = pd.read_csv(work_dir + 'WT_metadata.tsv', sep=\"\\t\", index_col=0)\n","\n","# Subset the reference DataFrame to only include the barcodes present in the query data\n","ref_df = metadata_df.loc[adata.obs_names.intersection(metadata_df.index)]\n","\n","# Assign the reference cluster annotations to the 'cell_state' column of the adata object\n","adata.obs['cell_state'] = ref_df['cell_state']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUqhqBjUgT--"},"outputs":[],"source":["adata.obs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kO7Nih1VgT--"},"outputs":[],"source":["adata.X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYqDrtOlgT--"},"outputs":[],"source":["#Subset the reference DataFrame to only include the barcodes present in the query data\n","ref_df = metadata_df.loc[adata.obs_names.intersection(metadata_df.index)]\n","\n","#Assign the reference cluster annotations to the 'clusters' column of the adata object\n","adata.obs['S.Score'] = ref_df['S.Score']\n","\n","#Assign the reference cluster annotations to the 'clusters' column of the adata object\n","adata.obs['G2M.Score'] = ref_df['G2M.Score']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5x9isJxgT--"},"outputs":[],"source":["#Perform downstream analysis on the data to see the effect of cell cycle\n","sc.tl.pca(adata)\n","sc.pp.neighbors(adata)\n","sc.tl.umap(adata)\n","sc.tl.leiden(adata)\n","\n","#Visualize the clustering\n","sc.pl.umap(adata, color=['G2M.Score', 'S.Score', 'cell_state'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5f1gak5gT-_"},"outputs":[],"source":["#Regressing out the cell cycle\n","sc.pp.regress_out(adata, ['S.Score', 'G2M.Score'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ZiNVVdwgT-_"},"outputs":[],"source":["#Perform downstream analysis on the corrected data\n","sc.tl.pca(adata)\n","sc.pp.neighbors(adata)\n","sc.tl.umap(adata)\n","sc.tl.leiden(adata)\n","\n","#Visualize the clustering with the corrected data\n","sc.pl.umap(adata, color=['G2M.Score', 'S.Score', 'cell_state'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRpyi2HdgT-_"},"outputs":[],"source":["sc.tl.leiden(adata, resolution = 0.5, key_added = 'leiden_res_0.5')\n","sc.pl.umap(adata, color = 'leiden_res_0.5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8hjyGfuigT-_"},"outputs":[],"source":["#Cleaning the annotation by running a clustering and assigning clusters to cell subtypes based on the maximum overlap. \n","\n","tmp_df = adata.obs.groupby(['leiden_res_0.5', 'cell_state']).size().unstack(fill_value=0)\n","tmp_df = (tmp_df / tmp_df.sum(0)).fillna(0)\n","leiden_to_annotation = tmp_df.idxmax(1).to_dict()\n","leiden_to_annotation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5vQeHqsgT-_"},"outputs":[],"source":["#As we can see, there are cell types that are in multiple clusters, so now we will group these clusters into one. Also, removing the spaces in this new annotation\n","leiden_to_annotation['4'] = 'H1 reduct'\n","leiden_to_annotation['1'] = 'H1 main' \n","leiden_to_annotation = {cluster: leiden_to_annotation[cluster].replace(' ', '_') for cluster in leiden_to_annotation.keys()}\n","leiden_to_annotation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTwG_SPugT_A"},"outputs":[],"source":["#Adding the annotation to the AnnData object\n","adata.obs['cell_type'] = [leiden_to_annotation[cluster_id] for cluster_id in adata.obs['leiden_res_0.5']]\n","del(leiden_to_annotation)\n","del(tmp_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nggI7D8CgT_A"},"outputs":[],"source":["adata.obs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNHRFxEhgT_A"},"outputs":[],"source":["#Final UMAP\n","sc.pl.umap(adata, color = 'cell_type')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RaeazF-2gT_A"},"outputs":[],"source":["adata.write(os.path.join(work_dir, 'scRNA/adata.h5ad'), compression='gzip')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"aVNpLW1hgT_A"},"source":["Now the pre-processing of the scRNA-seq data has ben done. With this, we filtered the cells with bad counts and obtained only the high quality cells. Also we annotated the cell types and made a clustering analysis to see how the different cells group. Also, the cell annotation is used later in the SCENIC+ pipeline. \n","\n","SCENIC+ uses the raw gene expression counts (without normalization and scaling). For that, we used the adata.raw to still keep the raw data of our scRNA-seq. \n","\n","Now, the next part of the pre-processing will be to analyze the scATAC-seq data. For this, we will use the cell annotation done in the scRNA-seq data pre-processing. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EItZ_Cz_gT_A"},"source":["# scATAC-seq preprocessing using pycisTopic\n","\n","Now, we preprocess the scATAC-seq side of the multiome dataset of EpRAS-wt cells. Now, we will generate pseudobulk ATAC-seq profiles per cell type and call peaks. These peaks then will be merged into a consensus peak-set, do qualityy control on the scATAC-seq barcodes and finally run topic modelling to find sets of co-accessible regions and impute chromatin accessibility. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"khNdVx94gT_B"},"outputs":[],"source":["import pandas as pd\n","import scipy.io as sio\n","import scipy.sparse as sp\n","import pycisTopic as ctp\n","import anndata as ad"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUo_ReM6gT_B"},"outputs":[],"source":["# Output directory\n","out_dir = work_dir + 'scATAC/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tU__ZFS4gT_C"},"outputs":[],"source":["#Writing temp directory\n","tmp_dir = work_dir + 'tmp_dir/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3T-rxLS7gT_C"},"outputs":[],"source":["import anndata as ad\n","# Load the cell annotation data from the .h5ad file\n","adata = ad.read(work_dir + 'scRNA/adata.h5ad')\n","cell_data = adata.obs\n","cell_data['sample_id'] = 'WT'\n","cell_data['cell_type'] = cell_data['cell_type'].astype(str) # set data type of the celltype column to str, otherwise the export_pseudobulk function will complain.\n","del(adata)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJIwJU3KgT_C"},"outputs":[],"source":["# Path to fragments\n","fragments_dict = {'WT': out_dir + 'fragments/atac_fragments_good.tsv.gz'}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1lfXnwPFgT_C"},"outputs":[],"source":["# Get chromosome sizes (for hg38 here)\n","import pyranges as pr\n","import requests\n","target_url='http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/mm10.chrom.sizes'\n","chromsizes=pd.read_csv(target_url, sep='\\t', header=None)\n","chromsizes.columns=['Chromosome', 'End']\n","chromsizes['Start']=[0]*chromsizes.shape[0]\n","chromsizes=chromsizes.loc[:,['Chromosome', 'Start', 'End']]\n","# Exceptionally in this case, to agree with CellRangerARC annotations\n","chromsizes['Chromosome'] = [chromsizes['Chromosome'][x].replace('v', '.') for x in range(len(chromsizes['Chromosome']))]\n","chromsizes['Chromosome'] = [chromsizes['Chromosome'][x].split('_')[1] if len(chromsizes['Chromosome'][x].split('_')) > 1 else chromsizes['Chromosome'][x] for x in range(len(chromsizes['Chromosome']))]\n","chromsizes=pr.PyRanges(chromsizes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84C1xEdXgT_C"},"outputs":[],"source":["from pycisTopic.pseudobulk_peak_calling import export_pseudobulk\n","bw_paths, bed_paths = export_pseudobulk(input_data = cell_data,\n","                 variable = 'cell_type',                                                                     # variable by which to generate pseubulk profiles, in this case we want pseudobulks per celltype\n","                 sample_id_col = 'sample_id',\n","                 chromsizes = chromsizes,\n","                 bed_path = os.path.join(out_dir, 'consensus_peak_calling/pseudobulk_bed_files/'),          # specify where pseudobulk_bed_files should be stored\n","                 bigwig_path = os.path.join(out_dir, 'consensus_peak_calling/pseudobulk_bw_files/'),        # specify where pseudobulk_bw_files should be stored\n","                 path_to_fragments = fragments_dict,                                                        # location of fragment fiels\n","                 n_cpu = 6,                                                                                 # specify the number of cores to use, we use ray for multi processing\n","                 normalize_bigwig = True,\n","                 remove_duplicates = True,\n","                 _temp_dir = os.path.join(tmp_dir, 'ray_spill'),\n","                 split_pattern = '-')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJ_OJ8VlgT_D"},"outputs":[],"source":["#Deactivate the virtual environment\n","!deactivate"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
